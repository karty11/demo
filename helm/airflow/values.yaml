image:
  repository: apache/airflow
  tag: "2.9.0"
  pullPolicy: IfNotPresent

# Executor - keep it simple
executor: "LocalExecutor"

# Airflow base configs
airflow:
  fernetKey: "your-fernet-key-here"   # generate with: openssl rand -base64 32
  secretKey: "super-secret-key"
  webserverSecretKey: "another-secret-key"
  config:
    AIRFLOW__CORE__LOAD_EXAMPLES: "False"
    AIRFLOW__CORE__EXECUTOR: "LocalExecutor"
  connections:
    - id: mysql_conn
      type: mysql
      host: mysql.devproject
      schema: bankappdb
      login: root
      # For demo: set via Kubernetes Secret or ESO
      password: "{{ .Values.mysql.rootPassword | default \"demo-pass\" }}"
      port: 3306
    - id: minio_conn
      type: s3
      extra: |
        {
          "aws_access_key_id": "minioadmin",
          "aws_secret_access_key": "minioadmin",
          "host": "http://minio.minio:9000",
          "region_name": "us-east-1"
        }

# Enable Postgres (Airflow metadata DB)
postgresql:
  enabled: true
  primary:
    persistence:
      enabled: true
      storageClass: gp3   # change to gp3 if gp2 fails

# Disable Redis (not needed for LocalExecutor)
redis:
  enabled: false

# Scheduler
scheduler:
  replicas: 1

# Webserver
web:
  replicas: 1
  service:
    type: ClusterIP
    port: 8080

# Disable Workers (only needed for CeleryExecutor)
workers:
  enabled: false

# Disable Triggerer (optional, keeps demo light)
triggerer:
  enabled: false

# DAGs config
dags:
  persistence:
    enabled: false
  path: /opt/airflow/dags
  gitSync:
    enabled: false

extraVolumes:
  - name: airflow-dags
    configMap:
      name: airflow-dags

extraVolumeMounts:
  - name: airflow-dags
    mountPath: /opt/airflow/dags
