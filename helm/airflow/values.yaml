image:
  repository: apache/airflow
  tag: "2.9.0"
  pullPolicy: IfNotPresent

# Executor
executor: "LocalExecutor"

airflow:
  # These secrets MUST exist or be generated before sync
  fernetKey: "replace-with-openssl-base64"       # openssl rand -base64 32
  webserverSecretKey: "replace-with-web-key"     # openssl rand -base64 32

  config:
    AIRFLOW__CORE__LOAD_EXAMPLES: "False"
    AIRFLOW__CORE__EXECUTOR: "LocalExecutor"

  # ✅ Auto-create connections inside Airflow metadata DB
  connections:
    - id: mysql_conn
      type: mysql
      host: mysql.devproject.svc.cluster.local
      schema: bankappdb
      login: root
      # password will be injected from K8s secret (see below)
      passwordSecret:
        name: bankapp-db-externalsecret
        key: "Test@123"
      port: 3306

    - id: minio_conn
      type: s3
      extra: |
        {
          "aws_access_key_id": "minioadmin",
          "aws_secret_access_key": "minioadmin",
          "host": "http://minio.minio:9000",
          "region_name": "us-east-1"
        }

# ✅ Use existing MySQL instead of bundled Postgres
externalDatabase:
  type: mysql
  host: mysql.devproject.svc.cluster.local
  port: 3306
  user: root
  passwordSecret:
    name: bankapp-db-externalsecret
    key: password
  database: bankappdb

# ❌ Disable bundled Postgres
postgresql:
  enabled: false

# Disable redis/triggerer (not needed for LocalExecutor)
redis:
  enabled: false
triggerer:
  enabled: false

logs:
  persistence:
    enabled: false   # don’t bother with PVCs for logs in demo

scheduler:
  replicas: 1

web:
  replicas: 1
  service:
    type: ClusterIP
    port: 8080

# DAGs handling
dags:
  persistence:
    enabled: false
  gitSync:
    enabled: false

extraVolumes:
  - name: airflow-dags
    configMap:
      name: airflow-dags

extraVolumeMounts:
  - name: airflow-dags
    mountPath: /opt/airflow/dags
